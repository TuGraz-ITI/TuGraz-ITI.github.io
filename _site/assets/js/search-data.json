{"0": {
    "doc": "About",
    "title": "About",
    "content": "D-Cube is hosted at the Institute of Technical Informatics of Graz University of Technology which also hosts a Wiki with further information on D-Cube, its history, and capabilities. The Wiki further contains an extensive list of contact information, however, in case something goes wrong and the Wiki is not available you can contact us at dcube(at)iti(dot)tugraz(dot)at. ",
    "url": "http://localhost:4000/about/",
    "relUrl": "/about/"
  },"1": {
    "doc": "Home",
    "title": "D-Cube: A Benchmark for Low-Power Wireless Systems",
    "content": "D-Cube is a full-fledged benchmarking infrastructure that provides a consistent way to evaluate the performance of low-power wireless systems. Hosted at the Institute of Technical Informatics of Graz University of Technology, D-Cube supports the automated testing of the reliability, timeliness, and energy consumption of low-power wireless communication protocols in a variety of settings. The primary audience of D-Cube are academic researchers and industry practitioners creating low-power wireless networking solutions that would like to quantitatively assess and compare their performance with that of other systems addressing the same class of applications. D-Cube is fully open source with the software licensed under the MIT License and PCB design files under Creative Commons Attribution Share Alike 4.0 International. This site serves as a quickstart guide to setup a new D-Cube instance using the provided source. ",
    "url": "http://localhost:4000/#d-cube-a-benchmark-for-low-power-wireless-systems",
    "relUrl": "/#d-cube-a-benchmark-for-low-power-wireless-systems"
  },"2": {
    "doc": "Home",
    "title": "Architecture",
    "content": "To install D-Cube on your local infrastrucutre, two components need to be set up: . | The Server-Side Components responsible for user interaction and orchestration of experiments | The testbed infrastructure made up of Observer Modules (using Raspberry Pi 3B and one or both custom PCBs) instrumenting the Target Nodes (currently nRF52840DK and TelosB Sky nodes are supported) | . ",
    "url": "http://localhost:4000/#architecture",
    "relUrl": "/#architecture"
  },"3": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },"4": {
    "doc": "Observer Module",
    "title": "Observer Module",
    "content": "Each Observer Module is based around a Raspberry Pi 3B and two custom PCBs: . | A measurement PCB (responsible for isolation of the target node, PoE power supply, asynchrnonous mailbox, and energy measurements) | A target mux PCB (to use more than once target node per observer module, or for the nRF52840DK to enable switching between the Segger JLink interface and the native USB port) | . To get started with the Observer Module, download the Raspberry Pi Image TBD. Write the provided image file to an SD card (e.g., using dd, etcher, or the official Raspberry Pi Imager). ",
    "url": "http://localhost:4000/observer-module",
    "relUrl": "/observer-module"
  },"5": {
    "doc": "Observer Module",
    "title": "Requirements",
    "content": "Each Observer Module requires a unique hostname which must be changed after writing the image (changing /etc/hostname and /etc/hosts) to rpiXXX (where XXX is the number of the Pi). After flashing the first Observer Module, further changes for the local network are required. Each module needs to know the address of the server running the Server-Side Components, to this end the following files need to be adapted: . | /etc/chrony/chrony.conf (in case the ntp is running on the server, otherwise also add the IP of the Raspberry running the GSP module) | /home/pi/dcm/rpc_pi.py (the Raspberry class needs to have the correct IP address of the broker/server) | /home/pi/testbed/influx-emiter.py and /home/pi/testbed/i2c/influx-emiter.py use the server’s IP in multiple locations | . Afterwards, this new base image can be replicated and only the hostname/hosts needs to be changed per Pi. ",
    "url": "http://localhost:4000/observer-module#requirements",
    "relUrl": "/observer-module#requirements"
  },"6": {
    "doc": "Observer Module",
    "title": "Architecture",
    "content": "The Observer Module is split into three (mostly) independent parts: . | The GPIO Tracing Unit constantly monitoring the Target Node’s GPIOs with the ability to control them in blocks of 4 GPIOs (along with reset and power). | The Latency Profiling Unit to enable synchrnoized measurements of the GPIOs across the testbed, GPS or NTP can be used. | The Power Profiling Unit uses and external synchronous sampling ADC to measure voltage and current of the target node. | . ",
    "url": "http://localhost:4000/observer-module#architecture",
    "relUrl": "/observer-module#architecture"
  },"7": {
    "doc": "Server-Side Components",
    "title": "Server-Side Components",
    "content": "To get started with the Server-Side Components, download the source by cloning the github repository . The Server-Side Components are intended to be run on a single central server with two networks: . | A public interface (with port 80 and/or 443 exposed for the web interface) | An airgap network for the Observer Modules | . While such a separation is not necessary for operation, it is still highly recommended. The easiest way to setup the server-side components is to use the provided docker-compose file. To do so, install and configure docker (or an alternative container engine like podman) and using docker-compose (or an equivalent tool) run . docker-compose build #this builds the dcube-web container from the github repository docker-compose up -d #this starts the services in the background . ",
    "url": "http://localhost:4000/server-side-components",
    "relUrl": "/server-side-components"
  },"8": {
    "doc": "Server-Side Components",
    "title": "Requirements",
    "content": "It is assumed that the server running D-Cube is located behind a reverse proxy (e.g., nginx) and/or firewall, as the container’s ports for http, influxdb, and amqp are opened. This guide will not cover these basic steps. Further, it is recommended to run a dhcp server for the airgap network. A good starting point is to run dnsmasq on the central server along the server-side components. To ensure proper timesync, either the server or an Observer Module should act as ntp server using chrony. ",
    "url": "http://localhost:4000/server-side-components#requirements",
    "relUrl": "/server-side-components#requirements"
  },"9": {
    "doc": "Server-Side Components",
    "title": "Architecture",
    "content": "The Server-Side Components are split into three (mostly) independent parts: . | The Measurement Stack using two containers for influxdb and grafana. | The Custom Front- and Backend using two containers for dcube-web and a mysql/mariadb database. | The Message Broker using a single container for rabbitmq. | . ",
    "url": "http://localhost:4000/server-side-components#architecture",
    "relUrl": "/server-side-components#architecture"
  }
}
